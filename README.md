# ğŸš€ HDM â€” Human Digital Memory

**HDM (Human Digital Memory)** is a local-first system designed to organize, classify, and index massive collections of images and videos (1TBâ€“50TB+) using advanced computer vision, multimodal embeddings, semantic clustering, and dynamic ontology generation â€” all running **100% offline** and accelerated by GPU.

HDM creates a structured â€œdigital memoryâ€ from raw unorganized media using a fully modular, scalable, and incremental architecture.

---

## ğŸ”¥ Key Features

### ğŸ§  Multimodal Embeddings
Fusion of:
- CLIP
- DINOv2
- MobileNet
- Optional Vision-LLM  
Combined into a single unified vector representation.

### ğŸ§© Semantic Classification
Automatic detection of:
- landscapes
- documents
- memes
- screenshots
- selfies
- WhatsApp content
- objects
- NSFW (local-only)
- and moreâ€¦

### ğŸ“· Face Engine
- Face detection  
- Embeddings (ArcFace/InsightFace)  
- Person clustering (HDBSCAN)  
- Persistent identity tracking  

### ğŸ” Duplicate Detection
- Perceptual hashing (pHash, aHash, wHash)  
- Deep embedding similarity  
- Direct + semantic duplicate identification  

### ğŸŒ«ï¸ Blur & Quality Analysis
- Laplacian variance  
- SVD sharpness  
- Aesthetic scoring  

### ğŸ§  Ontology Builder
Creates dynamic, human-friendly categories such as:
- â€œBeach Trip 2023â€
- â€œDocuments â€” Invoicesâ€
- â€œWhatsApp Screenshots with Johnâ€
- â€œFamily â€” Momâ€

### ğŸ” Vector Indexing
- FAISS or Qdrant  
- Incremental upsert  
- k-NN semantic search  

---

## ğŸ—ï¸ Architecture Overview

HDM is organized into four immutable macro-layers:

```
Application Layer      â†’ CLI, Web UI, API  
HDM Core Layer         â†’ Pipelines, Embeddings, Face Engine, Classifiers, Ontology, Reasoner  
Data & Storage Layer   â†’ Vector DB, Metadata Store, Cache  
System Layer           â†’ Filesystem, IO, CUDA/GPU  
```

Pipeline:

```
SCAN â†’ LOAD â†’ EMBED â†’ BLUR/DUPLICATES â†’ FACES â†’ SEMANTIC/NSFW  
â†’ CLUSTER â†’ ONTOLOGY â†’ REASONER â†’ INDEX â†’ ORGANIZER
```

---

## âš™ï¸ Core Principles

- Local-first (no cloud uploads)
- Modular architecture
- Scalable to tens of millions of files
- Incremental processing
- GPU-accelerated
- Fully interpretable (logs + semantic reasoning)
- Extensible and model-agnostic
- TDD-first development methodology

---

## ğŸ“ Project Structure

```
HDM/
 â”œâ”€â”€ hdm_core/
 â”‚    â”œâ”€â”€ io/
 â”‚    â”œâ”€â”€ embeddings/
 â”‚    â”œâ”€â”€ clustering/
 â”‚    â”œâ”€â”€ models/
 â”‚    â”œâ”€â”€ ontology/
 â”‚    â”œâ”€â”€ reasoner/
 â”‚    â”œâ”€â”€ pipelines/
 â”‚    â”œâ”€â”€ index/
 â”‚    â””â”€â”€ utils/
 â”œâ”€â”€ hdm_cli/
 â”œâ”€â”€ hdm_web/
 â””â”€â”€ tests/
```

---

## ğŸš€ Roadmap

### âœ” Completed
- Foundation Spec  
- High-Level Architecture  

### ğŸ— In Progress
- Interfaces (Protocols)  
- Technical Contracts  
- Detailed Pipelines  
- Base Implementations (ImageLoader, EmbeddingEngine)

### â­ Planned
- Full Orchestration Engine  
- Web Interface  
- Person Timeline  
- Memory Search System  
- Offline Vision-LLM integration

---

## ğŸ” Privacy & Security

- 100% offline  
- No media files leave the user's system  
- NSFW classification runs locally  
- No personal data included in repo  

---

## ğŸ“œ License

Open Software License ("OSL") v 3.0)

---

## ğŸ§‘â€ğŸ’» Author

HDM â€” Human Digital Memory  
Andre Pinheiro
